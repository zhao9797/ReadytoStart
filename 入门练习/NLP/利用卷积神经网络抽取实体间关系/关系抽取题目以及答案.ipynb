{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 题目：利用卷积神经网络抽取实体间关系\n",
    "* 参考论文：Relation classification via convolutional deep neural network.2014. COLING\n",
    "* 参考框架、工具：python3.x、pytorch1.x\n",
    "* 作业难度较大\n",
    "* 使用技术手段：word2vec、CNN、MaxPooling\n",
    "* 推荐数据集：关系抽取数据集SemEval2010 task8（可以用任意其他关系抽取数据集完成）\n",
    "* 推荐词向量：Glove \n",
    "* 本项目包含：1.数据集构造（预处理）、2. 模型搭建和训练、3. 模型测试和展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入依赖包和设置需求路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:32:38.672687Z",
     "start_time": "2020-08-30T06:32:38.197959Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import os, json\n",
    "import torch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:32:56.844274Z",
     "start_time": "2020-08-30T06:32:56.254615Z"
    }
   },
   "outputs": [],
   "source": [
    "root_path = \"datasets\"\n",
    "rel2id = os.path.join(root_path, 'data/semeval/semeval_rel2id.json') #关系id映射\n",
    "train_path = os.path.join(root_path, 'data/semeval/semeval_train.txt')  # 训练集路径\n",
    "val_path = os.path.join(root_path, 'data/semeval/semeval_val.txt') #验证集路径\n",
    "test_path = os.path.join(root_path, 'data/semeval/semeval_test.txt')#测试集路径\n",
    "word2id = json.load(open(os.path.join(root_path, 'glove/glove_word2id.json'))) #词id\n",
    "word2vec = os.path.join(root_path, 'glove/glove_mat.npy') #词向量\n",
    "ckpt = 'best_acc.pth.tar' #保存参数路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:32:59.957491Z",
     "start_time": "2020-08-30T06:32:59.953494Z"
    }
   },
   "outputs": [],
   "source": [
    "#超参数设置\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "lr = 0.1\n",
    "weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:33:02.561999Z",
     "start_time": "2020-08-30T06:33:02.537015Z"
    }
   },
   "outputs": [],
   "source": [
    "class REDataset(data.Dataset):#创建数据集\n",
    "    def __init__(self, path, rel2id_path, word2id, max_length=40):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.rel2id = json.load(open(rel2id_path))\n",
    "        self.id2rel = {v: k for k, v in self.rel2id.items()}\n",
    "        # Load the file\n",
    "        f = open(path, encoding='utf-8')\n",
    "        self.data = []\n",
    "        for line in f.readlines():\n",
    "            line = line.rstrip()\n",
    "            if len(line) > 0:\n",
    "                self.data.append(eval(line))\n",
    "        f.close()\n",
    "        self.word2id = word2id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        seq = list(self.tokenize(item['token'], item['h']['pos'], item['t']['pos']))\n",
    "        return [self.rel2id[item['relation']]] + seq  # label, seq1, seq2, ...\n",
    "\n",
    "    def tokenize(self, raw_tokens, pos_head, pos_tail):\n",
    "        # token -> index，构造相对位置编码和词id\n",
    "        indexed_tokens = []\n",
    "        for token in raw_tokens:\n",
    "            token = token.lower()\n",
    "            if token in self.word2id:\n",
    "                indexed_tokens.append(self.word2id[token])\n",
    "            else:\n",
    "                indexed_tokens.append(self.word2id['[UNK]'])\n",
    "\n",
    "        # padding\n",
    "        while len(indexed_tokens) < self.max_length:\n",
    "            indexed_tokens.append(self.word2id['[PAD]'])\n",
    "        indexed_tokens = indexed_tokens[:self.max_length]\n",
    "\n",
    "        # pos\n",
    "        pos1 = np.zeros((self.max_length), dtype=np.int32)\n",
    "        pos2 = np.zeros((self.max_length), dtype=np.int32)\n",
    "        pos1_in_index = min(self.max_length, pos_head[0])\n",
    "        pos2_in_index = min(self.max_length, pos_tail[0])\n",
    "        for i in range(self.max_length):\n",
    "            pos1[i] = i - pos1_in_index + self.max_length\n",
    "            pos2[i] = i - pos2_in_index + self.max_length\n",
    "        indexed_tokens = torch.tensor(indexed_tokens).long()\n",
    "        pos1 = torch.tensor(pos1).long()\n",
    "        pos2 = torch.tensor(pos2).long()\n",
    "\n",
    "        return indexed_tokens, pos1, pos2#词id，实体1的相对位置编码和实体2的相对位置编码\n",
    "    @staticmethod\n",
    "    def collate_fn(data):\n",
    "        data = list(zip(*data))\n",
    "        labels = data[0]\n",
    "        batch_labels = torch.tensor(labels).long()\n",
    "        seqs = data[1:]\n",
    "        batch_seqs = []\n",
    "        for seq in seqs:\n",
    "            batch_seqs.append(pad_sequence(seq, batch_first=True, padding_value=0))\n",
    "        return [batch_labels] + batch_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:33:06.030029Z",
     "start_time": "2020-08-30T06:33:05.027587Z"
    }
   },
   "outputs": [],
   "source": [
    "#创建训练所需的DataLoader\n",
    "train_dataset = REDataset(path=train_path, rel2id_path=rel2id, word2id=word2id)\n",
    "val_dataset = REDataset(path=val_path, rel2id_path=rel2id, word2id=word2id)\n",
    "test_dataset = REDataset(path=test_path, rel2id_path=rel2id, word2id=word2id)\n",
    "\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=0,\n",
    "                                  collate_fn=REDataset.collate_fn)\n",
    "val_loader = data.DataLoader(dataset=val_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=0,\n",
    "                                  collate_fn=REDataset.collate_fn)\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=0,\n",
    "                                  collate_fn=REDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:33:10.010734Z",
     "start_time": "2020-08-30T06:33:09.995746Z"
    }
   },
   "outputs": [],
   "source": [
    "#构建词嵌入模块\n",
    "class Embedding(nn.Module):\n",
    "\n",
    "    def __init__(self, word_vec_mat, max_length, word_embedding_dim=50, pos_embedding_dim=5):\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "        self.pos_embedding_dim = pos_embedding_dim\n",
    "\n",
    "        # Word embedding\n",
    "        # unk = torch.randn(1, word_embedding_dim) / math.sqrt(word_embedding_dim)\n",
    "        # blk = torch.zeros(1, word_embedding_dim)\n",
    "        word_vec_mat = np.load(word_vec_mat)\n",
    "        word_vec_mat = torch.from_numpy(word_vec_mat)\n",
    "        self.word_embedding = nn.Embedding(word_vec_mat.shape[0], self.word_embedding_dim,\n",
    "                                           padding_idx=word_vec_mat.shape[0] - 1)\n",
    "        self.word_embedding.weight.data.copy_(word_vec_mat)\n",
    "\n",
    "        # Position Embedding\n",
    "        self.pos1_embedding = nn.Embedding(2 * max_length, pos_embedding_dim, padding_idx=0)\n",
    "        self.pos2_embedding = nn.Embedding(2 * max_length, pos_embedding_dim, padding_idx=0)\n",
    "\n",
    "    def forward(self, word, pos1, pos2):\n",
    "        x = torch.cat([self.word_embedding(word),\n",
    "                       self.pos1_embedding(pos1),\n",
    "                       self.pos2_embedding(pos2)], 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:33:10.659361Z",
     "start_time": "2020-08-30T06:33:10.651369Z"
    }
   },
   "outputs": [],
   "source": [
    "#CNN 上下文编码模块\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, max_length, word_embedding_dim=50, pos_embedding_dim=5, hidden_size=230):\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_dim = word_embedding_dim + pos_embedding_dim * 2\n",
    "        self.conv = nn.Conv1d(self.embedding_dim, self.hidden_size, 3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(max_length)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.cnn(inputs)\n",
    "\n",
    "    def cnn(self, inputs):\n",
    "        x = self.conv(inputs.transpose(1, 2))\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x.squeeze(2) # n x hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:33:11.588828Z",
     "start_time": "2020-08-30T06:33:11.576854Z"
    }
   },
   "outputs": [],
   "source": [
    "#主模型搭建\n",
    "class CNNRC(nn.Module):\n",
    "    def __init__(self, word_vec_mat, max_length):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.embed = Embedding(word_vec_mat, max_length) #词嵌入\n",
    "        self.encoder = Encoder(max_length)#卷积编码\n",
    "        self.fc = nn.Linear(self.encoder.hidden_size, 19)#分类层\n",
    "\n",
    "    def forward(self, word, pos1, pos2):\n",
    "        x = self.embed(word, pos1, pos2)\n",
    "        x = self.encoder(x)\n",
    "        x = self.fc(x)\n",
    "        _, pred = torch.max(x.view(-1, 19), 1)\n",
    "        return x, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:33:17.584394Z",
     "start_time": "2020-08-30T06:33:14.658069Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNNRC(word_vec_mat= word2vec, max_length=40) #初始化模型\n",
    "#设置优化器SGD\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr, weight_decay=weight_decay)\n",
    "#设置交叉熵损失函数\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:33:20.952465Z",
     "start_time": "2020-08-30T06:33:20.940470Z"
    }
   },
   "outputs": [],
   "source": [
    "def epoch(t, train=False):#训练一个epoch的流程\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    loss_log = 0.0\n",
    "    acc_log = 0.0\n",
    "    for iters, data in enumerate(t):\n",
    "        # sentence\n",
    "        label = data[0]\n",
    "        args = data[1:]\n",
    "        logits, pred = model(*args)\n",
    "        # loss\n",
    "        loss = loss_func(logits, label)\n",
    "        acc = float((pred == label).long().sum()) / label.size(0)\n",
    "        # Log\n",
    "        loss_log += loss.item()\n",
    "        acc_log += acc\n",
    "        sys.stdout.write( \"iters : {}, loss : {:.4f}, acc:{:.4f}\".format(iters+1, loss_log/(iters+1), acc_log/(iters+1))+'\\r')\n",
    "        sys.stdout.flush()\n",
    "        # Optimize\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    return acc_log/(iters+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:33:25.970589Z",
     "start_time": "2020-08-30T06:33:25.960595Z"
    }
   },
   "outputs": [],
   "source": [
    "def train():#完整训练过程\n",
    "    best_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        print(\"\\nepoch {} tarin\".format(i))\n",
    "        epoch(train_loader, train=True)\n",
    "        print(\"\\nepoch {} val\".format(i))\n",
    "        acc = epoch(val_loader)\n",
    "        print(\"\\nval result: {:.4f}\".format(acc))\n",
    "        sys.stdout.flush()\n",
    "        if acc > best_acc:\n",
    "            print(\"\\nBest ckpt and saved.\")\n",
    "            torch.save({'state_dict': model.state_dict()}, ckpt)\n",
    "            best_acc = acc\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "    print(\"test\")\n",
    "    acc = epoch(test_loader)\n",
    "    print(\"test result: {:.4f}\".format(acc))#在测试集上的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T05:45:47.291822Z",
     "start_time": "2020-08-28T05:38:33.043916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 tarin\n",
      "epoch 0 val, loss : 0.2430, acc:0.9366\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "Best ckpt and saved.\n",
      "epoch 1 tarin\n",
      "epoch 1 val, loss : 0.2433, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 2 tarin\n",
      "epoch 2 val, loss : 0.2429, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 3 tarin\n",
      "epoch 3 val, loss : 0.2428, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 4 tarin\n",
      "epoch 4 val, loss : 0.2428, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 5 tarin\n",
      "epoch 5 val, loss : 0.2429, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 6 tarin\n",
      "epoch 6 val, loss : 0.2432, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 7 tarin\n",
      "epoch 7 val, loss : 0.2446, acc:0.9363\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 8 tarin\n",
      "epoch 8 val, loss : 0.2435, acc:0.9366\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 9 tarin\n",
      "epoch 9 val, loss : 0.2427, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 10 tarin\n",
      "epoch 10 val loss : 0.2430, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 11 tarin\n",
      "epoch 11 val loss : 0.2431, acc:0.9366\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 12 tarin\n",
      "epoch 12 val loss : 0.2440, acc:0.9366\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 13 tarin\n",
      "epoch 13 val loss : 0.2428, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 14 tarin\n",
      "epoch 14 val loss : 0.2445, acc:0.9363\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 15 tarin\n",
      "epoch 15 val loss : 0.2436, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 16 tarin\n",
      "epoch 16 val loss : 0.2433, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 17 tarin\n",
      "epoch 17 val loss : 0.2431, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 18 tarin\n",
      "epoch 18 val loss : 0.2428, acc:0.9369\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "epoch 19 tarin\n",
      "epoch 19 val loss : 0.2452, acc:0.9360\n",
      "iters : 47, loss : 1.0002, acc:0.7152\n",
      "val result: 0.7152\n",
      "test\n",
      "test result: 0.71770.9911, acc:0.7177\n"
     ]
    }
   ],
   "source": [
    "# 模型训练和测试\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用训练好的模型展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:33:40.554300Z",
     "start_time": "2020-08-30T06:33:38.558376Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNNRC(word_vec_mat= word2vec, max_length=40)\n",
    "checkpoint = torch.load(ckpt) #加载训练好的参数\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "def demo(x, h, t):\n",
    "    ori = x\n",
    "    x = x.strip().split()\n",
    "    head, tail = x[h[0]:h[-1]], x[t[0]:t[-1]]\n",
    "    token, h, t = test_dataset.tokenize(x, h, t)\n",
    "    token = token.unsqueeze(0)\n",
    "    h = h.unsqueeze(0)\n",
    "    t = t.unsqueeze(0)\n",
    "    args = [token, h, t]\n",
    "    _, pred = model(*args)\n",
    "    pred = int(pred[0].item())\n",
    "    print(\"This sentense is:\")\n",
    "    print(ori)\n",
    "    print(\"head(e1) :{}, tail(e2) : {}\".format(head, tail))\n",
    "    print(\"predict is:\")\n",
    "    print(test_dataset.id2rel[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T06:34:09.301762Z",
     "start_time": "2020-08-30T06:34:09.267781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentense is:\n",
      "Like magic , a covert of coots arrives to feed on whatever there is in the lake bottom .\n",
      "head(e1) :['coots'], tail(e2) : ['covert']\n",
      "predict is:\n",
      "Product-Producer(e2,e1)\n"
     ]
    }
   ],
   "source": [
    "#展示效果\n",
    "x = \"Like magic , a covert of coots arrives to feed on whatever there is in the lake bottom .\"\n",
    "h = [6, 7]\n",
    "t = [4, 5]\n",
    "demo(x, h, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
